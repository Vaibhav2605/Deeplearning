{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neha7598/Deeplearning/blob/master/EmotionClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMzUWfnQb1d4",
        "colab_type": "code",
        "outputId": "fa78d0e8-297a-4a70-dc95-5c04bfd92231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96y7lpMXb9re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs8h--gRcBwe",
        "colab_type": "code",
        "outputId": "c7d23932-03c3-4bd7-cd85-f33281f3b6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Conv2D \n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation, Dropout, MaxPooling2D, Flatten, Dense\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qXS3HY2dfOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(dataset_path):\n",
        "  \n",
        "  data = []\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "  labels =[]\n",
        "\n",
        "  with open(dataset_path, 'r') as file:\n",
        "      for line_no, line in enumerate(file.readlines()):\n",
        "          if 0 < line_no <= 35887:\n",
        "            c_class, line, set_type = line.split(',')\n",
        "            image_data = np.asarray([int(x) for x in line.split()]).reshape(48, 48)\n",
        "            image_data =image_data.astype(np.uint8)/255.0\n",
        "            \n",
        "            if (set_type.strip() =='PrivateTest'):\n",
        "              test_data.append(image_data)\n",
        "              test_labels.append(c_class)\n",
        "              \n",
        "            else:\n",
        "              data.append(image_data)\n",
        "              labels.append(c_class)\n",
        "      \n",
        "      test_data = np.expand_dims(test_data, -1)\n",
        "      test_labels = to_categorical(test_labels, num_classes = 7)\n",
        "      data = np.expand_dims(data, -1)   \n",
        "      labels = to_categorical(labels, num_classes = 7)\n",
        "    \n",
        "      return np.array(data), np.array(labels), np.array(test_data), np.array(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v36NtJHdlt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset= \"/content/drive/My Drive/Colab Notebooks/Emotion Recognition/data/fer2013.csv\" \n",
        "train_data, train_labels, test_data, test_labels = load_data(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSfVv7OldpYz",
        "colab_type": "code",
        "outputId": "284eb2e5-0bdb-4053-df08-fce7319c5ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Number of Examples in train_set= \", len(train_data))\n",
        "print(\"Number of Examples in test_set= \", len(test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Examples in train_set=  32298\n",
            "Number of Examples in test_set=  3589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90wk0cw0fYaU",
        "colab_type": "code",
        "outputId": "c1f67981-9274-4b54-fa58-bd873eb45168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "width=48\n",
        "height=48\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2048, activation= 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "adam = optimizers.Adam(lr = learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0809 07:38:54.989458 140134416996224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0809 07:38:55.038568 140134416996224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0809 07:38:55.045861 140134416996224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0809 07:38:55.093994 140134416996224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0809 07:38:55.095232 140134416996224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0809 07:38:57.901814 140134416996224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0809 07:38:58.054657 140134416996224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0809 07:38:58.065617 140134416996224 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0809 07:38:58.923966 140134416996224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 11,577,799\n",
            "Trainable params: 11,573,959\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__r9YqXWgxEL",
        "colab_type": "code",
        "outputId": "e5d4ff1b-232f-4617-adb6-13d0a75c71be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model.fit(\n",
        "          train_data,\n",
        "          train_labels,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.2,\n",
        "          shuffle = True,\n",
        "          \n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0809 07:39:17.012167 140134416996224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 25838 samples, validate on 6460 samples\n",
            "Epoch 1/100\n",
            "25838/25838 [==============================] - 33s 1ms/step - loss: 2.1024 - acc: 0.2167 - val_loss: 1.8189 - val_acc: 0.2489\n",
            "Epoch 2/100\n",
            "25838/25838 [==============================] - 26s 1ms/step - loss: 1.8460 - acc: 0.2504 - val_loss: 1.8184 - val_acc: 0.2489\n",
            "Epoch 3/100\n",
            "25838/25838 [==============================] - 26s 1ms/step - loss: 1.8205 - acc: 0.2543 - val_loss: 1.7904 - val_acc: 0.2508\n",
            "Epoch 4/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.7403 - acc: 0.2965 - val_loss: 1.6733 - val_acc: 0.2895\n",
            "Epoch 5/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.6732 - acc: 0.3251 - val_loss: 1.7101 - val_acc: 0.3085\n",
            "Epoch 6/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.6166 - acc: 0.3534 - val_loss: 1.5382 - val_acc: 0.4014\n",
            "Epoch 7/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.5791 - acc: 0.3696 - val_loss: 1.6657 - val_acc: 0.2994\n",
            "Epoch 8/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.5313 - acc: 0.3895 - val_loss: 1.4706 - val_acc: 0.3992\n",
            "Epoch 9/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.5094 - acc: 0.3966 - val_loss: 1.4050 - val_acc: 0.4141\n",
            "Epoch 10/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.4825 - acc: 0.4107 - val_loss: 1.3659 - val_acc: 0.4324\n",
            "Epoch 11/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.4508 - acc: 0.4171 - val_loss: 1.3804 - val_acc: 0.4376\n",
            "Epoch 12/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.4341 - acc: 0.4251 - val_loss: 1.3796 - val_acc: 0.4319\n",
            "Epoch 13/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.4296 - acc: 0.4211 - val_loss: 1.8110 - val_acc: 0.2396\n",
            "Epoch 14/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.4204 - acc: 0.4288 - val_loss: 1.4422 - val_acc: 0.4232\n",
            "Epoch 15/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.3879 - acc: 0.4453 - val_loss: 1.4734 - val_acc: 0.3889\n",
            "Epoch 16/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.3772 - acc: 0.4532 - val_loss: 1.3022 - val_acc: 0.4954\n",
            "Epoch 17/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.3496 - acc: 0.4673 - val_loss: 1.2804 - val_acc: 0.5023\n",
            "Epoch 18/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.3355 - acc: 0.4749 - val_loss: 1.2822 - val_acc: 0.5118\n",
            "Epoch 19/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.3155 - acc: 0.4814 - val_loss: 1.2587 - val_acc: 0.5302\n",
            "Epoch 20/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.3041 - acc: 0.4949 - val_loss: 1.2836 - val_acc: 0.5262\n",
            "Epoch 21/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.2796 - acc: 0.5045 - val_loss: 1.2424 - val_acc: 0.5231\n",
            "Epoch 22/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.2562 - acc: 0.5129 - val_loss: 1.2129 - val_acc: 0.5328\n",
            "Epoch 23/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.2449 - acc: 0.5260 - val_loss: 1.2788 - val_acc: 0.5116\n",
            "Epoch 24/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.2246 - acc: 0.5307 - val_loss: 1.1879 - val_acc: 0.5531\n",
            "Epoch 25/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.1877 - acc: 0.5448 - val_loss: 1.3303 - val_acc: 0.4726\n",
            "Epoch 26/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.1737 - acc: 0.5562 - val_loss: 1.1914 - val_acc: 0.5689\n",
            "Epoch 27/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.1718 - acc: 0.5591 - val_loss: 1.1724 - val_acc: 0.5697\n",
            "Epoch 28/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.1514 - acc: 0.5667 - val_loss: 1.1857 - val_acc: 0.5498\n",
            "Epoch 29/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.1236 - acc: 0.5719 - val_loss: 1.2146 - val_acc: 0.5310\n",
            "Epoch 30/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.1102 - acc: 0.5823 - val_loss: 1.1820 - val_acc: 0.5590\n",
            "Epoch 31/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.0898 - acc: 0.5922 - val_loss: 1.1531 - val_acc: 0.5834\n",
            "Epoch 32/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.0787 - acc: 0.5975 - val_loss: 1.1504 - val_acc: 0.5813\n",
            "Epoch 33/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.0658 - acc: 0.6014 - val_loss: 1.1334 - val_acc: 0.5859\n",
            "Epoch 34/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.0616 - acc: 0.6067 - val_loss: 1.1690 - val_acc: 0.5706\n",
            "Epoch 35/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.0376 - acc: 0.6153 - val_loss: 1.1919 - val_acc: 0.5735\n",
            "Epoch 36/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.0217 - acc: 0.6220 - val_loss: 1.1255 - val_acc: 0.6029\n",
            "Epoch 37/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.0116 - acc: 0.6302 - val_loss: 1.1316 - val_acc: 0.5912\n",
            "Epoch 38/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 1.0069 - acc: 0.6295 - val_loss: 1.1412 - val_acc: 0.6043\n",
            "Epoch 39/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.9995 - acc: 0.6382 - val_loss: 1.1217 - val_acc: 0.5991\n",
            "Epoch 40/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.9697 - acc: 0.6467 - val_loss: 1.0991 - val_acc: 0.6040\n",
            "Epoch 41/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.9611 - acc: 0.6514 - val_loss: 1.1433 - val_acc: 0.6073\n",
            "Epoch 42/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.9459 - acc: 0.6562 - val_loss: 1.1179 - val_acc: 0.6011\n",
            "Epoch 43/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.9285 - acc: 0.6640 - val_loss: 1.1383 - val_acc: 0.5910\n",
            "Epoch 44/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.9258 - acc: 0.6658 - val_loss: 1.2013 - val_acc: 0.5754\n",
            "Epoch 45/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.9115 - acc: 0.6729 - val_loss: 1.1308 - val_acc: 0.5981\n",
            "Epoch 46/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.8996 - acc: 0.6784 - val_loss: 1.1107 - val_acc: 0.6063\n",
            "Epoch 47/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.8873 - acc: 0.6814 - val_loss: 1.0989 - val_acc: 0.6111\n",
            "Epoch 48/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.8809 - acc: 0.6845 - val_loss: 1.1000 - val_acc: 0.6026\n",
            "Epoch 49/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.8699 - acc: 0.6888 - val_loss: 1.1300 - val_acc: 0.5974\n",
            "Epoch 50/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.8448 - acc: 0.6963 - val_loss: 1.1531 - val_acc: 0.6006\n",
            "Epoch 51/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.8399 - acc: 0.7030 - val_loss: 1.1001 - val_acc: 0.6082\n",
            "Epoch 52/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.8385 - acc: 0.7051 - val_loss: 1.0951 - val_acc: 0.6119\n",
            "Epoch 53/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.8181 - acc: 0.7088 - val_loss: 1.1107 - val_acc: 0.6183\n",
            "Epoch 54/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.8087 - acc: 0.7194 - val_loss: 1.0968 - val_acc: 0.6087\n",
            "Epoch 55/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7908 - acc: 0.7184 - val_loss: 1.1150 - val_acc: 0.6200\n",
            "Epoch 56/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7887 - acc: 0.7246 - val_loss: 1.1492 - val_acc: 0.6193\n",
            "Epoch 57/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7863 - acc: 0.7260 - val_loss: 1.0965 - val_acc: 0.6214\n",
            "Epoch 58/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7733 - acc: 0.7329 - val_loss: 1.1274 - val_acc: 0.6169\n",
            "Epoch 59/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7599 - acc: 0.7319 - val_loss: 1.1399 - val_acc: 0.6108\n",
            "Epoch 60/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7540 - acc: 0.7369 - val_loss: 1.1412 - val_acc: 0.6266\n",
            "Epoch 61/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7471 - acc: 0.7400 - val_loss: 1.1359 - val_acc: 0.6054\n",
            "Epoch 62/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7353 - acc: 0.7433 - val_loss: 1.1347 - val_acc: 0.6158\n",
            "Epoch 63/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7356 - acc: 0.7446 - val_loss: 1.1311 - val_acc: 0.6181\n",
            "Epoch 64/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7183 - acc: 0.7518 - val_loss: 1.1045 - val_acc: 0.6289\n",
            "Epoch 65/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.7119 - acc: 0.7550 - val_loss: 1.1131 - val_acc: 0.6271\n",
            "Epoch 66/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6946 - acc: 0.7633 - val_loss: 1.1411 - val_acc: 0.6311\n",
            "Epoch 67/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6978 - acc: 0.7599 - val_loss: 1.1246 - val_acc: 0.6212\n",
            "Epoch 68/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6915 - acc: 0.7598 - val_loss: 1.1753 - val_acc: 0.6186\n",
            "Epoch 69/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6774 - acc: 0.7696 - val_loss: 1.1148 - val_acc: 0.6277\n",
            "Epoch 70/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6661 - acc: 0.7728 - val_loss: 1.1947 - val_acc: 0.6133\n",
            "Epoch 71/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6693 - acc: 0.7674 - val_loss: 1.1423 - val_acc: 0.6176\n",
            "Epoch 72/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6727 - acc: 0.7694 - val_loss: 1.1729 - val_acc: 0.6245\n",
            "Epoch 73/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6468 - acc: 0.7800 - val_loss: 1.1300 - val_acc: 0.6167\n",
            "Epoch 74/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6460 - acc: 0.7818 - val_loss: 1.1385 - val_acc: 0.6240\n",
            "Epoch 75/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6458 - acc: 0.7803 - val_loss: 1.1328 - val_acc: 0.6300\n",
            "Epoch 76/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6312 - acc: 0.7859 - val_loss: 1.1651 - val_acc: 0.6190\n",
            "Epoch 77/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6382 - acc: 0.7828 - val_loss: 1.1422 - val_acc: 0.6176\n",
            "Epoch 78/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6235 - acc: 0.7916 - val_loss: 1.1427 - val_acc: 0.6310\n",
            "Epoch 79/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6161 - acc: 0.7893 - val_loss: 1.1789 - val_acc: 0.6328\n",
            "Epoch 80/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6068 - acc: 0.7941 - val_loss: 1.1621 - val_acc: 0.6294\n",
            "Epoch 81/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5929 - acc: 0.8007 - val_loss: 1.1976 - val_acc: 0.6307\n",
            "Epoch 82/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5936 - acc: 0.8020 - val_loss: 1.1329 - val_acc: 0.6313\n",
            "Epoch 83/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5865 - acc: 0.8070 - val_loss: 1.1572 - val_acc: 0.6291\n",
            "Epoch 84/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5805 - acc: 0.8067 - val_loss: 1.2063 - val_acc: 0.6359\n",
            "Epoch 85/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5637 - acc: 0.8097 - val_loss: 1.2255 - val_acc: 0.6255\n",
            "Epoch 86/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5722 - acc: 0.8100 - val_loss: 1.1979 - val_acc: 0.6259\n",
            "Epoch 87/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.6029 - acc: 0.7999 - val_loss: 1.1503 - val_acc: 0.6271\n",
            "Epoch 88/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5725 - acc: 0.8088 - val_loss: 1.2183 - val_acc: 0.6132\n",
            "Epoch 89/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5529 - acc: 0.8156 - val_loss: 1.1591 - val_acc: 0.6259\n",
            "Epoch 90/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5444 - acc: 0.8189 - val_loss: 1.1724 - val_acc: 0.6370\n",
            "Epoch 91/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5432 - acc: 0.8176 - val_loss: 1.1418 - val_acc: 0.6324\n",
            "Epoch 92/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5291 - acc: 0.8250 - val_loss: 1.1886 - val_acc: 0.6327\n",
            "Epoch 93/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5299 - acc: 0.8238 - val_loss: 1.1311 - val_acc: 0.6404\n",
            "Epoch 94/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5175 - acc: 0.8299 - val_loss: 1.1660 - val_acc: 0.6254\n",
            "Epoch 95/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5211 - acc: 0.8289 - val_loss: 1.2072 - val_acc: 0.6337\n",
            "Epoch 96/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5278 - acc: 0.8318 - val_loss: 1.1740 - val_acc: 0.6305\n",
            "Epoch 97/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.5068 - acc: 0.8348 - val_loss: 1.2184 - val_acc: 0.6361\n",
            "Epoch 98/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.4883 - acc: 0.8393 - val_loss: 1.1925 - val_acc: 0.6354\n",
            "Epoch 99/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.4955 - acc: 0.8370 - val_loss: 1.2076 - val_acc: 0.6393\n",
            "Epoch 100/100\n",
            "25838/25838 [==============================] - 27s 1ms/step - loss: 0.4884 - acc: 0.8394 - val_loss: 1.2637 - val_acc: 0.6353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73430542e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG4asRL3hMi6",
        "colab_type": "code",
        "outputId": "c815966f-2b48-43c4-bc7f-b28ff254e344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predicted_test_labels = np.argmax(model.predict(test_data), axis=1)\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "print (\"Accuracy  = \", accuracy_score(test_labels, predicted_test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy  =  0.6422401783226526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldCyi8MCnmAw",
        "colab_type": "code",
        "outputId": "269fa645-dd35-4b1f-c1b2-d4c82c0e2449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Emotion Recognition/models/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"/content/drive/My Drive/Colab Notebooks/Emotion Recognition/models/model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpQMscSEFWsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}